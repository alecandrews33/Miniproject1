{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('training_data.txt', skiprows=1)\n",
    "\n",
    "X = data[:, 1:]\n",
    "y = data[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.divide(X, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X[0: 10000]\n",
    "x_test = X[10000: ]\n",
    "\n",
    "y_train = y[0: 10000]\n",
    "y_test = y[10000: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1000, input_shape=(1000,)))  # Use np.reshape instead of this in hw\n",
    "model.add(Activation('softmax'))\n",
    "model.add(Dropout(0.13))\n",
    "model.add(Dense(600))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.08))\n",
    "\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "fit = model.fit(x_train, y_train, batch_size=128, epochs=25, verbose=1)\n",
    "\n",
    "## Printing the accuracy of our model, according to the loss function specified in model.compile above\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ********************************\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ******************************\n",
    "\n",
    "\n",
    "# ********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(200, kernel_initializer = 'normal', input_shape=(1000,)))  # Use np.reshape instead of this in hw\n",
    "model.add(Activation('softplus'))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(75))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "fit = model.fit(x_train, y_train, batch_size=128, epochs=30, verbose=1)\n",
    "\n",
    "## Printing the accuracy of our model, according to the loss function specified in model.compile above\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''*******\n",
    "\n",
    "\n",
    "\n",
    "******\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*******'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, kernel_initializer = 'normal', input_shape=(1000,)))  # Use np.reshape instead of this in hw\n",
    "model.add(Activation('softplus'))\n",
    "model.add(Dropout(0.10))\n",
    "model.add(Dense(75))\n",
    "model.add(Activation('softplus'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(25))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "fit = model.fit(x_train, y_train, batch_size=128, epochs=60, verbose=1)\n",
    "\n",
    "## Printing the accuracy of our model, according to the loss function specified in model.compile above\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = [0, 1, 2, 7, 9 ,10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "10000/10000 [==============================] - 2s 156us/step - loss: 0.6937 - acc: 0.5086\n",
      "Epoch 2/60\n",
      "10000/10000 [==============================] - 1s 82us/step - loss: 0.6923 - acc: 0.5139\n",
      "Epoch 3/60\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.6879 - acc: 0.5483\n",
      "Epoch 4/60\n",
      "10000/10000 [==============================] - 1s 119us/step - loss: 0.6611 - acc: 0.5973\n",
      "Epoch 5/60\n",
      "10000/10000 [==============================] - 1s 99us/step - loss: 0.5706 - acc: 0.7022\n",
      "Epoch 6/60\n",
      "10000/10000 [==============================] - 1s 81us/step - loss: 0.5167 - acc: 0.7489\n",
      "Epoch 7/60\n",
      "10000/10000 [==============================] - 1s 82us/step - loss: 0.4766 - acc: 0.7714\n",
      "Epoch 8/60\n",
      "10000/10000 [==============================] - 1s 81us/step - loss: 0.4657 - acc: 0.7790\n",
      "Epoch 9/60\n",
      "10000/10000 [==============================] - 1s 79us/step - loss: 0.4413 - acc: 0.7917\n",
      "Epoch 10/60\n",
      "10000/10000 [==============================] - 1s 79us/step - loss: 0.4371 - acc: 0.7970\n",
      "Epoch 11/60\n",
      "10000/10000 [==============================] - 1s 78us/step - loss: 0.4253 - acc: 0.8017\n",
      "Epoch 12/60\n",
      "10000/10000 [==============================] - 1s 82us/step - loss: 0.4167 - acc: 0.8069\n",
      "Epoch 13/60\n",
      "10000/10000 [==============================] - 1s 80us/step - loss: 0.4130 - acc: 0.8067\n",
      "Epoch 14/60\n",
      "10000/10000 [==============================] - 1s 85us/step - loss: 0.4013 - acc: 0.8188\n",
      "Epoch 15/60\n",
      "10000/10000 [==============================] - 1s 116us/step - loss: 0.3897 - acc: 0.8219\n",
      "Epoch 16/60\n",
      "10000/10000 [==============================] - 1s 101us/step - loss: 0.3893 - acc: 0.8216\n",
      "Epoch 17/60\n",
      "10000/10000 [==============================] - 1s 96us/step - loss: 0.3858 - acc: 0.8259\n",
      "Epoch 18/60\n",
      "10000/10000 [==============================] - 1s 92us/step - loss: 0.3843 - acc: 0.8289\n",
      "Epoch 19/60\n",
      "10000/10000 [==============================] - 1s 89us/step - loss: 0.3768 - acc: 0.8331\n",
      "Epoch 20/60\n",
      "10000/10000 [==============================] - 1s 83us/step - loss: 0.3767 - acc: 0.8315\n",
      "Epoch 21/60\n",
      "10000/10000 [==============================] - 1s 80us/step - loss: 0.3700 - acc: 0.8351\n",
      "Epoch 22/60\n",
      "10000/10000 [==============================] - 1s 79us/step - loss: 0.3666 - acc: 0.8357\n",
      "Epoch 23/60\n",
      "10000/10000 [==============================] - 1s 78us/step - loss: 0.3669 - acc: 0.8305\n",
      "Epoch 24/60\n",
      "10000/10000 [==============================] - 1s 78us/step - loss: 0.3724 - acc: 0.8348\n",
      "Epoch 25/60\n",
      "10000/10000 [==============================] - 1s 83us/step - loss: 0.3666 - acc: 0.8392\n",
      "Epoch 26/60\n",
      "10000/10000 [==============================] - 1s 81us/step - loss: 0.3545 - acc: 0.8422\n",
      "Epoch 27/60\n",
      "10000/10000 [==============================] - 1s 91us/step - loss: 0.3558 - acc: 0.8423\n",
      "Epoch 28/60\n",
      "10000/10000 [==============================] - 1s 91us/step - loss: 0.3566 - acc: 0.8413\n",
      "Epoch 29/60\n",
      "10000/10000 [==============================] - 1s 96us/step - loss: 0.3559 - acc: 0.8389\n",
      "Epoch 30/60\n",
      "10000/10000 [==============================] - 1s 98us/step - loss: 0.3580 - acc: 0.8402\n",
      "Epoch 31/60\n",
      "10000/10000 [==============================] - 1s 91us/step - loss: 0.3569 - acc: 0.8426\n",
      "Epoch 32/60\n",
      "10000/10000 [==============================] - 1s 98us/step - loss: 0.3498 - acc: 0.8464\n",
      "Epoch 33/60\n",
      "10000/10000 [==============================] - 1s 120us/step - loss: 0.3445 - acc: 0.8509\n",
      "Epoch 34/60\n",
      "10000/10000 [==============================] - 1s 94us/step - loss: 0.3443 - acc: 0.8510\n",
      "Epoch 35/60\n",
      "10000/10000 [==============================] - 1s 85us/step - loss: 0.3417 - acc: 0.8502\n",
      "Epoch 36/60\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.3464 - acc: 0.8462\n",
      "Epoch 37/60\n",
      "10000/10000 [==============================] - 1s 85us/step - loss: 0.3461 - acc: 0.8484\n",
      "Epoch 38/60\n",
      "10000/10000 [==============================] - 1s 82us/step - loss: 0.3434 - acc: 0.8510\n",
      "Epoch 39/60\n",
      "10000/10000 [==============================] - 1s 84us/step - loss: 0.3353 - acc: 0.8554\n",
      "Epoch 40/60\n",
      "10000/10000 [==============================] - 1s 111us/step - loss: 0.3363 - acc: 0.8545\n",
      "Epoch 41/60\n",
      "10000/10000 [==============================] - 1s 113us/step - loss: 0.3345 - acc: 0.8525\n",
      "Epoch 42/60\n",
      "10000/10000 [==============================] - 1s 112us/step - loss: 0.3349 - acc: 0.8538\n",
      "Epoch 43/60\n",
      "10000/10000 [==============================] - 1s 91us/step - loss: 0.3371 - acc: 0.8532\n",
      "Epoch 44/60\n",
      "10000/10000 [==============================] - 1s 84us/step - loss: 0.3361 - acc: 0.8539\n",
      "Epoch 45/60\n",
      "10000/10000 [==============================] - 1s 82us/step - loss: 0.3305 - acc: 0.8573\n",
      "Epoch 46/60\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.3301 - acc: 0.8593\n",
      "Epoch 47/60\n",
      "10000/10000 [==============================] - 1s 109us/step - loss: 0.3321 - acc: 0.8555\n",
      "Epoch 48/60\n",
      "10000/10000 [==============================] - 1s 86us/step - loss: 0.3294 - acc: 0.8599\n",
      "Epoch 49/60\n",
      "10000/10000 [==============================] - 1s 82us/step - loss: 0.3274 - acc: 0.8616\n",
      "Epoch 50/60\n",
      "10000/10000 [==============================] - 1s 83us/step - loss: 0.3323 - acc: 0.8585\n",
      "Epoch 51/60\n",
      "10000/10000 [==============================] - 1s 103us/step - loss: 0.3305 - acc: 0.8564\n",
      "Epoch 52/60\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.3222 - acc: 0.8647\n",
      "Epoch 53/60\n",
      "10000/10000 [==============================] - 1s 89us/step - loss: 0.3265 - acc: 0.8581\n",
      "Epoch 54/60\n",
      "10000/10000 [==============================] - 1s 95us/step - loss: 0.3223 - acc: 0.8600\n",
      "Epoch 55/60\n",
      "10000/10000 [==============================] - 1s 101us/step - loss: 0.3274 - acc: 0.8581\n",
      "Epoch 56/60\n",
      "10000/10000 [==============================] - 1s 104us/step - loss: 0.3211 - acc: 0.8628\n",
      "Epoch 57/60\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 0.3175 - acc: 0.8638\n",
      "Epoch 58/60\n",
      "10000/10000 [==============================] - 1s 110us/step - loss: 0.3166 - acc: 0.8676\n",
      "Epoch 59/60\n",
      "10000/10000 [==============================] - 1s 110us/step - loss: 0.3167 - acc: 0.8633\n",
      "Epoch 60/60\n",
      "10000/10000 [==============================] - 1s 108us/step - loss: 0.3172 - acc: 0.8629\n",
      "Test score: 0.365585580468\n",
      "Test accuracy: 0.8447\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(200, input_dim=1000, kernel_initializer='normal', activation='softplus'))\n",
    "model.add(Dropout(0.19))\n",
    "model.add(Dense(75))\n",
    "model.add(Activation('softplus'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(25))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "fit = model.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1)\n",
    "\n",
    "## Printing the accuracy of our model, according to the loss function specified in model.compile above\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(250, input_dim=1000, kernel_initializer='normal', activation='softplus'))\n",
    "    model.add(Dropout(0.19))\n",
    "    model.add(Dense(125))\n",
    "    model.add(Activation('softplus'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(40))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "14999/14999 [==============================] - 23s 2ms/step - loss: 0.6202 - acc: 0.6126\n",
      "Epoch 2/10\n",
      "14999/14999 [==============================] - 21s 1ms/step - loss: 0.4359 - acc: 0.7971\n",
      "Epoch 3/10\n",
      "14999/14999 [==============================] - 20s 1ms/step - loss: 0.4027 - acc: 0.8175\n",
      "Epoch 4/10\n",
      "14999/14999 [==============================] - 20s 1ms/step - loss: 0.3822 - acc: 0.8289\n",
      "Epoch 5/10\n",
      "14999/14999 [==============================] - 20s 1ms/step - loss: 0.3663 - acc: 0.8362\n",
      "Epoch 6/10\n",
      "14999/14999 [==============================] - 20s 1ms/step - loss: 0.3609 - acc: 0.8411\n",
      "Epoch 7/10\n",
      "14999/14999 [==============================] - 20s 1ms/step - loss: 0.3562 - acc: 0.8444\n",
      "Epoch 8/10\n",
      "14999/14999 [==============================] - 19s 1ms/step - loss: 0.3477 - acc: 0.8492\n",
      "Epoch 9/10\n",
      "14999/14999 [==============================] - 19s 1ms/step - loss: 0.3386 - acc: 0.8546\n",
      "Epoch 10/10\n",
      "14999/14999 [==============================] - 20s 1ms/step - loss: 0.3390 - acc: 0.8530\n",
      "5001/5001 [==============================] - 2s 423us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.6145 - acc: 0.6218\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.4306 - acc: 0.8007\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.3968 - acc: 0.8186\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.3717 - acc: 0.8368\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.3649 - acc: 0.8394\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.3546 - acc: 0.8486\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.3429 - acc: 0.8504\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 24s 2ms/step - loss: 0.3406 - acc: 0.8537\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.3326 - acc: 0.8551\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 20s 1ms/step - loss: 0.3317 - acc: 0.8575\n",
      "5000/5000 [==============================] - 2s 438us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_59 (Dense)             (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.6290 - acc: 0.6049\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 19s 1ms/step - loss: 0.4369 - acc: 0.8009\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.3929 - acc: 0.8233\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 20s 1ms/step - loss: 0.3664 - acc: 0.8397\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.3623 - acc: 0.8416\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.3544 - acc: 0.8469\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.3425 - acc: 0.8527\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 20s 1ms/step - loss: 0.3362 - acc: 0.8554\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.3314 - acc: 0.8597\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.3302 - acc: 0.8577\n",
      "5000/5000 [==============================] - 2s 486us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_63 (Dense)             (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.6429 - acc: 0.5809\n",
      "Epoch 2/10\n",
      "15001/15001 [==============================] - 20s 1ms/step - loss: 0.4410 - acc: 0.7950\n",
      "Epoch 3/10\n",
      "15001/15001 [==============================] - 20s 1ms/step - loss: 0.3958 - acc: 0.8200\n",
      "Epoch 4/10\n",
      "15001/15001 [==============================] - 19s 1ms/step - loss: 0.3793 - acc: 0.8297\n",
      "Epoch 5/10\n",
      "15001/15001 [==============================] - 19s 1ms/step - loss: 0.3619 - acc: 0.8414\n",
      "Epoch 6/10\n",
      "15001/15001 [==============================] - 19s 1ms/step - loss: 0.3584 - acc: 0.8410\n",
      "Epoch 7/10\n",
      "15001/15001 [==============================] - 19s 1ms/step - loss: 0.3534 - acc: 0.8459\n",
      "Epoch 8/10\n",
      "15001/15001 [==============================] - 19s 1ms/step - loss: 0.3412 - acc: 0.8529\n",
      "Epoch 9/10\n",
      "15001/15001 [==============================] - 21s 1ms/step - loss: 0.3377 - acc: 0.8537\n",
      "Epoch 10/10\n",
      "15001/15001 [==============================] - 21s 1ms/step - loss: 0.3339 - acc: 0.8552\n",
      "4999/4999 [==============================] - 2s 496us/step\n",
      "Results: 84.68% (1.05%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_model, epochs=10, batch_size=5, verbose=1)\n",
    "kfold = StratifiedKFold(n_splits=4)\n",
    "results = cross_val_score(estimator, X, y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('training_data.txt', skiprows=1)\n",
    "\n",
    "X_std = data[:, 1:]\n",
    "y_std = data[:, 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "14999/14999 [==============================] - 23s 2ms/step - loss: 0.4164 - acc: 0.8117\n",
      "Epoch 2/10\n",
      "14999/14999 [==============================] - 20s 1ms/step - loss: 0.3220 - acc: 0.8631\n",
      "Epoch 3/10\n",
      "14999/14999 [==============================] - 20s 1ms/step - loss: 0.2782 - acc: 0.8828\n",
      "Epoch 4/10\n",
      "14999/14999 [==============================] - 20s 1ms/step - loss: 0.2272 - acc: 0.9032\n",
      "Epoch 5/10\n",
      "14999/14999 [==============================] - 20s 1ms/step - loss: 0.1760 - acc: 0.9256\n",
      "Epoch 6/10\n",
      "14999/14999 [==============================] - 20s 1ms/step - loss: 0.1354 - acc: 0.9453\n",
      "Epoch 7/10\n",
      "14999/14999 [==============================] - 20s 1ms/step - loss: 0.1030 - acc: 0.9607\n",
      "Epoch 8/10\n",
      "14999/14999 [==============================] - 20s 1ms/step - loss: 0.0762 - acc: 0.9738\n",
      "Epoch 9/10\n",
      "14999/14999 [==============================] - 20s 1ms/step - loss: 0.0572 - acc: 0.9803\n",
      "Epoch 10/10\n",
      "14999/14999 [==============================] - 21s 1ms/step - loss: 0.0539 - acc: 0.9819\n",
      "5001/5001 [==============================] - 3s 565us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_71 (Dense)             (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 26s 2ms/step - loss: 0.4088 - acc: 0.8173\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.3103 - acc: 0.8681\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.2675 - acc: 0.8852\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.2231 - acc: 0.9060\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 20s 1ms/step - loss: 0.1714 - acc: 0.9277\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.1329 - acc: 0.9471\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.0994 - acc: 0.9636\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.0755 - acc: 0.9745\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 20s 1ms/step - loss: 0.0612 - acc: 0.9803\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 20s 1ms/step - loss: 0.0492 - acc: 0.9843\n",
      "5000/5000 [==============================] - 2s 460us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_75 (Dense)             (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.4079 - acc: 0.8159\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.3078 - acc: 0.8674\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.2628 - acc: 0.8912\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.2164 - acc: 0.9071\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.1766 - acc: 0.9253\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.1292 - acc: 0.9477\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.1030 - acc: 0.9595\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.0739 - acc: 0.9725\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.0656 - acc: 0.9775\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.0541 - acc: 0.9809\n",
      "5000/5000 [==============================] - 3s 517us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_79 (Dense)             (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.4146 - acc: 0.8123\n",
      "Epoch 2/10\n",
      "15001/15001 [==============================] - 20s 1ms/step - loss: 0.3114 - acc: 0.8685\n",
      "Epoch 3/10\n",
      "15001/15001 [==============================] - 20s 1ms/step - loss: 0.2712 - acc: 0.8841\n",
      "Epoch 4/10\n",
      "15001/15001 [==============================] - 29s 2ms/step - loss: 0.2190 - acc: 0.9045\n",
      "Epoch 5/10\n",
      "15001/15001 [==============================] - 25s 2ms/step - loss: 0.1716 - acc: 0.9297\n",
      "Epoch 6/10\n",
      "15001/15001 [==============================] - 22s 1ms/step - loss: 0.1200 - acc: 0.9521\n",
      "Epoch 7/10\n",
      "15001/15001 [==============================] - 22s 1ms/step - loss: 0.0894 - acc: 0.9675\n",
      "Epoch 8/10\n",
      "15001/15001 [==============================] - 22s 1ms/step - loss: 0.0703 - acc: 0.9757\n",
      "Epoch 9/10\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.0553 - acc: 0.9819\n",
      "Epoch 10/10\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.0500 - acc: 0.9830\n",
      "4999/4999 [==============================] - 3s 534us/step\n",
      "Standardized: 82.91% (0.40%)\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_model, epochs=10, batch_size=5, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=4)\n",
    "results = cross_val_score(pipeline, X_std, y_std, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('training_data.txt', skiprows=1)\n",
    "\n",
    "X_count = data[:, 1:]\n",
    "y_count = data[:, 0]\n",
    "\n",
    "for i in(range(len(X_count))):\n",
    "    for j in(range(len(X_count[0]))):\n",
    "        if X_count[i][j] != 0:\n",
    "            X_count[i][j] = 1\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_87 (Dense)             (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "14999/14999 [==============================] - 23s 2ms/step - loss: 0.4322 - acc: 0.8005\n",
      "Epoch 2/10\n",
      "14999/14999 [==============================] - 21s 1ms/step - loss: 0.3506 - acc: 0.8465\n",
      "Epoch 3/10\n",
      "14999/14999 [==============================] - 21s 1ms/step - loss: 0.3317 - acc: 0.8523\n",
      "Epoch 4/10\n",
      "14999/14999 [==============================] - 21s 1ms/step - loss: 0.3141 - acc: 0.8573\n",
      "Epoch 5/10\n",
      "14999/14999 [==============================] - 21s 1ms/step - loss: 0.2957 - acc: 0.8662\n",
      "Epoch 6/10\n",
      "14999/14999 [==============================] - 21s 1ms/step - loss: 0.2812 - acc: 0.8714\n",
      "Epoch 7/10\n",
      "14999/14999 [==============================] - 21s 1ms/step - loss: 0.2594 - acc: 0.8794\n",
      "Epoch 8/10\n",
      "14999/14999 [==============================] - 22s 1ms/step - loss: 0.2334 - acc: 0.8913\n",
      "Epoch 9/10\n",
      "14999/14999 [==============================] - 27s 2ms/step - loss: 0.2007 - acc: 0.9094\n",
      "Epoch 10/10\n",
      "14999/14999 [==============================] - 26s 2ms/step - loss: 0.1712 - acc: 0.9243\n",
      "5001/5001 [==============================] - 3s 673us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_91 (Dense)             (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 33s 2ms/step - loss: 0.4216 - acc: 0.7997\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 24s 2ms/step - loss: 0.3461 - acc: 0.8489\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 24s 2ms/step - loss: 0.3258 - acc: 0.8581\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 24s 2ms/step - loss: 0.3088 - acc: 0.8615\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 25s 2ms/step - loss: 0.2923 - acc: 0.8697\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 26s 2ms/step - loss: 0.2774 - acc: 0.8739\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 29s 2ms/step - loss: 0.2556 - acc: 0.8869\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 24s 2ms/step - loss: 0.2278 - acc: 0.8963\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.1907 - acc: 0.9131\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.1582 - acc: 0.9323\n",
      "5000/5000 [==============================] - 3s 576us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_95 (Dense)             (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 25s 2ms/step - loss: 0.4309 - acc: 0.7992\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 25s 2ms/step - loss: 0.3420 - acc: 0.8535\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 24s 2ms/step - loss: 0.3219 - acc: 0.8609\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.3076 - acc: 0.8655\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - ETA: 0s - loss: 0.2903 - acc: 0.872 - 26s 2ms/step - loss: 0.2901 - acc: 0.8723\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 26s 2ms/step - loss: 0.2729 - acc: 0.8798\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 25s 2ms/step - loss: 0.2528 - acc: 0.8915\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 27s 2ms/step - loss: 0.2266 - acc: 0.9028\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 26s 2ms/step - loss: 0.1904 - acc: 0.9167\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 26s 2ms/step - loss: 0.1541 - acc: 0.9347\n",
      "5000/5000 [==============================] - 3s 610us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_99 (Dense)             (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15001/15001 [==============================] - 26s 2ms/step - loss: 0.4272 - acc: 0.7991\n",
      "Epoch 2/10\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.3478 - acc: 0.8502\n",
      "Epoch 3/10\n",
      "15001/15001 [==============================] - 24s 2ms/step - loss: 0.3262 - acc: 0.8567\n",
      "Epoch 4/10\n",
      "15001/15001 [==============================] - 24s 2ms/step - loss: 0.3116 - acc: 0.8611\n",
      "Epoch 5/10\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.2968 - acc: 0.8684\n",
      "Epoch 6/10\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.2779 - acc: 0.8709\n",
      "Epoch 7/10\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.2589 - acc: 0.8819\n",
      "Epoch 8/10\n",
      "15001/15001 [==============================] - 24s 2ms/step - loss: 0.2332 - acc: 0.8949\n",
      "Epoch 9/10\n",
      "15001/15001 [==============================] - 24s 2ms/step - loss: 0.1942 - acc: 0.9151\n",
      "Epoch 10/10\n",
      "15001/15001 [==============================] - 24s 2ms/step - loss: 0.1601 - acc: 0.9316\n",
      "4999/4999 [==============================] - 4s 732us/step\n",
      "Results: 83.30% (0.37%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_model, epochs=10, batch_size=5, verbose=1)\n",
    "kfold = StratifiedKFold(n_splits=4)\n",
    "results = cross_val_score(estimator, X_count, y_count, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('training_data.txt', skiprows=1)\n",
    "\n",
    "X_negs = data[:, 1:]\n",
    "y_negs = data[:, 0]\n",
    "\n",
    "for i in(range(len(X_negs))):\n",
    "    for j in(range(len(X_negs[0]))):\n",
    "        if X_negs[i][j] == 0:\n",
    "            X_negs[i][j] = -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_111 (Dense)            (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "14999/14999 [==============================] - 26s 2ms/step - loss: 0.6069 - acc: 0.6440\n",
      "Epoch 2/10\n",
      "14999/14999 [==============================] - 23s 2ms/step - loss: 0.4595 - acc: 0.7848\n",
      "Epoch 3/10\n",
      "14999/14999 [==============================] - 24s 2ms/step - loss: 0.4291 - acc: 0.8027\n",
      "Epoch 4/10\n",
      "14999/14999 [==============================] - 22s 1ms/step - loss: 0.4019 - acc: 0.8201\n",
      "Epoch 5/10\n",
      "14999/14999 [==============================] - 23s 2ms/step - loss: 0.3926 - acc: 0.8248\n",
      "Epoch 6/10\n",
      "14999/14999 [==============================] - 25s 2ms/step - loss: 0.3833 - acc: 0.8284\n",
      "Epoch 7/10\n",
      "14999/14999 [==============================] - 24s 2ms/step - loss: 0.3774 - acc: 0.8300\n",
      "Epoch 8/10\n",
      "14999/14999 [==============================] - 25s 2ms/step - loss: 0.3771 - acc: 0.8283\n",
      "Epoch 9/10\n",
      "14999/14999 [==============================] - 23s 2ms/step - loss: 0.3646 - acc: 0.8373\n",
      "Epoch 10/10\n",
      "14999/14999 [==============================] - 22s 1ms/step - loss: 0.3621 - acc: 0.8389\n",
      "5001/5001 [==============================] - 3s 626us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_115 (Dense)            (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 27s 2ms/step - loss: 0.6025 - acc: 0.6519\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 25s 2ms/step - loss: 0.4584 - acc: 0.7832\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 25s 2ms/step - loss: 0.4194 - acc: 0.8093\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 26s 2ms/step - loss: 0.3985 - acc: 0.8202\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 26s 2ms/step - loss: 0.3890 - acc: 0.8203\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 27s 2ms/step - loss: 0.3824 - acc: 0.8289\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 34s 2ms/step - loss: 0.3734 - acc: 0.8325\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 36s 2ms/step - loss: 0.3641 - acc: 0.8367\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 25s 2ms/step - loss: 0.3582 - acc: 0.8406\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 25s 2ms/step - loss: 0.3558 - acc: 0.8403\n",
      "5000/5000 [==============================] - 3s 625us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_119 (Dense)            (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 28s 2ms/step - loss: 0.5898 - acc: 0.6631\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 25s 2ms/step - loss: 0.4505 - acc: 0.7897\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 28s 2ms/step - loss: 0.4124 - acc: 0.8137\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 26s 2ms/step - loss: 0.3965 - acc: 0.8243\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 27s 2ms/step - loss: 0.3874 - acc: 0.8237\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 25s 2ms/step - loss: 0.3829 - acc: 0.8273\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 26s 2ms/step - loss: 0.3782 - acc: 0.8293\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 26s 2ms/step - loss: 0.3652 - acc: 0.8372\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 26s 2ms/step - loss: 0.3627 - acc: 0.8418\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 26s 2ms/step - loss: 0.3602 - acc: 0.8399\n",
      "5000/5000 [==============================] - 3s 628us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_123 (Dense)            (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15001/15001 [==============================] - 24s 2ms/step - loss: 0.6192 - acc: 0.6292\n",
      "Epoch 2/10\n",
      "15001/15001 [==============================] - 20s 1ms/step - loss: 0.4631 - acc: 0.7853\n",
      "Epoch 3/10\n",
      "15001/15001 [==============================] - 22s 1ms/step - loss: 0.4299 - acc: 0.8053\n",
      "Epoch 4/10\n",
      "15001/15001 [==============================] - 21s 1ms/step - loss: 0.4042 - acc: 0.8180\n",
      "Epoch 5/10\n",
      "15001/15001 [==============================] - 21s 1ms/step - loss: 0.3903 - acc: 0.8172\n",
      "Epoch 6/10\n",
      "15001/15001 [==============================] - 21s 1ms/step - loss: 0.3859 - acc: 0.8287\n",
      "Epoch 7/10\n",
      "15001/15001 [==============================] - 24s 2ms/step - loss: 0.3782 - acc: 0.8283\n",
      "Epoch 8/10\n",
      "15001/15001 [==============================] - 21s 1ms/step - loss: 0.3733 - acc: 0.8331\n",
      "Epoch 9/10\n",
      "15001/15001 [==============================] - 21s 1ms/step - loss: 0.3660 - acc: 0.8341\n",
      "Epoch 10/10\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.3594 - acc: 0.8404\n",
      "4999/4999 [==============================] - 3s 646us/step\n",
      "Results: 83.72% (0.16%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_model, epochs=10, batch_size=5, verbose=1)\n",
    "kfold = StratifiedKFold(n_splits=4)\n",
    "results = cross_val_score(estimator, X_negs, y_negs, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      " -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('training_data.txt', skiprows=1)\n",
    "\n",
    "X_binar = data[:, 1:]\n",
    "y_binar = data[:, 0]\n",
    "\n",
    "for i in(range(len(X_binar))):\n",
    "    for j in(range(len(X_binar[0]))):\n",
    "        if X_binar[i][j] == 0:\n",
    "            X_binar[i][j] = -1\n",
    "        else:\n",
    "            X_binar[i][j] = 1\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_127 (Dense)            (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "14999/14999 [==============================] - 26s 2ms/step - loss: 0.6599 - acc: 0.5792\n",
      "Epoch 2/10\n",
      "14999/14999 [==============================] - 24s 2ms/step - loss: 0.5043 - acc: 0.7519\n",
      "Epoch 3/10\n",
      "14999/14999 [==============================] - 24s 2ms/step - loss: 0.4592 - acc: 0.7813\n",
      "Epoch 4/10\n",
      "14999/14999 [==============================] - 24s 2ms/step - loss: 0.4371 - acc: 0.7942\n",
      "Epoch 5/10\n",
      "14999/14999 [==============================] - 25s 2ms/step - loss: 0.4299 - acc: 0.7961\n",
      "Epoch 6/10\n",
      "14999/14999 [==============================] - 24s 2ms/step - loss: 0.4249 - acc: 0.7971\n",
      "Epoch 7/10\n",
      "14999/14999 [==============================] - 24s 2ms/step - loss: 0.4090 - acc: 0.8067\n",
      "Epoch 8/10\n",
      "14999/14999 [==============================] - 24s 2ms/step - loss: 0.4006 - acc: 0.8081\n",
      "Epoch 9/10\n",
      "14999/14999 [==============================] - 24s 2ms/step - loss: 0.3947 - acc: 0.8113\n",
      "Epoch 10/10\n",
      "14999/14999 [==============================] - 24s 2ms/step - loss: 0.3862 - acc: 0.8175\n",
      "5001/5001 [==============================] - 3s 653us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_131 (Dense)            (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 24s 2ms/step - loss: 0.6539 - acc: 0.5806\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.4817 - acc: 0.7688\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.4417 - acc: 0.7982\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.4267 - acc: 0.8081\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.4024 - acc: 0.8179\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.4048 - acc: 0.8145\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.3971 - acc: 0.8239\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.3909 - acc: 0.8279\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.3775 - acc: 0.8353\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.3789 - acc: 0.8332\n",
      "5000/5000 [==============================] - 4s 705us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_135 (Dense)            (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 27s 2ms/step - loss: 0.6233 - acc: 0.6303\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.4688 - acc: 0.7800\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.4340 - acc: 0.7988\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.4140 - acc: 0.8139\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.4018 - acc: 0.8239\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.3964 - acc: 0.8237\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 24s 2ms/step - loss: 0.3823 - acc: 0.8309\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 25s 2ms/step - loss: 0.3785 - acc: 0.8322\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 26s 2ms/step - loss: 0.3725 - acc: 0.8356\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.3737 - acc: 0.8329\n",
      "5000/5000 [==============================] - 3s 696us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_139 (Dense)            (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15001/15001 [==============================] - 25s 2ms/step - loss: 0.6385 - acc: 0.6115\n",
      "Epoch 2/10\n",
      "15001/15001 [==============================] - 24s 2ms/step - loss: 0.4830 - acc: 0.7713\n",
      "Epoch 3/10\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.4431 - acc: 0.7945\n",
      "Epoch 4/10\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.4205 - acc: 0.8078\n",
      "Epoch 5/10\n",
      "15001/15001 [==============================] - 25s 2ms/step - loss: 0.4088 - acc: 0.8123\n",
      "Epoch 6/10\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.4023 - acc: 0.8217\n",
      "Epoch 7/10\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.3939 - acc: 0.8222\n",
      "Epoch 8/10\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.3853 - acc: 0.8280\n",
      "Epoch 9/10\n",
      "15001/15001 [==============================] - 22s 1ms/step - loss: 0.3755 - acc: 0.8323\n",
      "Epoch 10/10\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.3745 - acc: 0.8288\n",
      "4999/4999 [==============================] - 3s 699us/step\n",
      "Results: 80.07% (3.85%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_model, epochs=10, batch_size=5, verbose=1)\n",
    "kfold = StratifiedKFold(n_splits=4)\n",
    "results = cross_val_score(estimator, X_binar, y_binar, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('training_data.txt', skiprows=1)\n",
    "\n",
    "Xp = data[:, 1:]\n",
    "yp = data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp[1613][11] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xp[1613][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [8, 9, 15, 60, 61, 77, 113, 119, 141, 148, 149, 161, 183, 211, 259, 305, 303, 324, 372, 390, 487, 530, 563,\n",
    "593, 716, 748, 760, 762, 781, 802, 880, 922, 966, 968, 812, 722, 675, 577]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_15 = Xp\n",
    "x_20 = Xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(x_15)):\n",
    "    for j in indices:\n",
    "        x_15[i][j] *= 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow = np.divide(x_15, 22.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13636364,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.06818182,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.04545455,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.04545455,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.04545455,  0.        ,  0.04545455,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.04545455,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.04545455,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.04545455,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.04545455,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.04545455,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.04545455,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.09090909,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.04545455,  0.        ,\n",
       "        0.        ,  0.04545455,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.04545455,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.04545455,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.04545455,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.04545455,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.04545455,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.04545455,  0.        ,\n",
       "        0.        ,  0.        ,  0.04545455,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.04545455,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.09090909,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bow[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_143 (Dense)            (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "14999/14999 [==============================] - 26s 2ms/step - loss: 0.6139 - acc: 0.6241\n",
      "Epoch 2/10\n",
      "14999/14999 [==============================] - 24s 2ms/step - loss: 0.4366 - acc: 0.7976\n",
      "Epoch 3/10\n",
      "14999/14999 [==============================] - 23s 2ms/step - loss: 0.3985 - acc: 0.8188\n",
      "Epoch 4/10\n",
      "14999/14999 [==============================] - 24s 2ms/step - loss: 0.3811 - acc: 0.8269\n",
      "Epoch 5/10\n",
      "14999/14999 [==============================] - 24s 2ms/step - loss: 0.3739 - acc: 0.8327\n",
      "Epoch 6/10\n",
      "14999/14999 [==============================] - 24s 2ms/step - loss: 0.3582 - acc: 0.8431\n",
      "Epoch 7/10\n",
      "14999/14999 [==============================] - 23s 2ms/step - loss: 0.3502 - acc: 0.8455\n",
      "Epoch 8/10\n",
      "14999/14999 [==============================] - 23s 2ms/step - loss: 0.3486 - acc: 0.8507\n",
      "Epoch 9/10\n",
      "14999/14999 [==============================] - 23s 2ms/step - loss: 0.3383 - acc: 0.8531\n",
      "Epoch 10/10\n",
      "14999/14999 [==============================] - 23s 2ms/step - loss: 0.3337 - acc: 0.8559\n",
      "5001/5001 [==============================] - 3s 639us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_147 (Dense)            (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.6316 - acc: 0.6025\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 24s 2ms/step - loss: 0.4312 - acc: 0.7983\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 24s 2ms/step - loss: 0.3935 - acc: 0.8223\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 24s 2ms/step - loss: 0.3774 - acc: 0.8320\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 24s 2ms/step - loss: 0.3628 - acc: 0.8380\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 24s 2ms/step - loss: 0.3530 - acc: 0.8417\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 24s 2ms/step - loss: 0.3434 - acc: 0.8517\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 24s 2ms/step - loss: 0.3411 - acc: 0.8533\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.3346 - acc: 0.8549\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.3288 - acc: 0.8574\n",
      "5000/5000 [==============================] - 4s 714us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_151 (Dense)            (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 25s 2ms/step - loss: 0.6751 - acc: 0.5334\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 24s 2ms/step - loss: 0.4463 - acc: 0.7942\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.3930 - acc: 0.8215\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.3731 - acc: 0.8351\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.3602 - acc: 0.8427\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.3516 - acc: 0.8506\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 24s 2ms/step - loss: 0.3437 - acc: 0.8536\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.3392 - acc: 0.8541\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 35s 2ms/step - loss: 0.3331 - acc: 0.8579\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 26s 2ms/step - loss: 0.3317 - acc: 0.8567\n",
      "5000/5000 [==============================] - 4s 777us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_155 (Dense)            (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15001/15001 [==============================] - 24s 2ms/step - loss: 0.6138 - acc: 0.6242\n",
      "Epoch 2/10\n",
      "15001/15001 [==============================] - 21s 1ms/step - loss: 0.4350 - acc: 0.7971\n",
      "Epoch 3/10\n",
      "15001/15001 [==============================] - 22s 1ms/step - loss: 0.3974 - acc: 0.8228\n",
      "Epoch 4/10\n",
      "15001/15001 [==============================] - 22s 1ms/step - loss: 0.3753 - acc: 0.8342\n",
      "Epoch 5/10\n",
      "15001/15001 [==============================] - 22s 1ms/step - loss: 0.3645 - acc: 0.8379\n",
      "Epoch 6/10\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.3577 - acc: 0.8474\n",
      "Epoch 7/10\n",
      "15001/15001 [==============================] - 22s 1ms/step - loss: 0.3495 - acc: 0.8474\n",
      "Epoch 8/10\n",
      "15001/15001 [==============================] - 22s 1ms/step - loss: 0.3457 - acc: 0.8506\n",
      "Epoch 9/10\n",
      "15001/15001 [==============================] - 25s 2ms/step - loss: 0.3395 - acc: 0.8557\n",
      "Epoch 10/10\n",
      "15001/15001 [==============================] - 25s 2ms/step - loss: 0.3369 - acc: 0.8522\n",
      "4999/4999 [==============================] - 4s 828us/step\n",
      "Results: 84.69% (0.65%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_model, epochs=10, batch_size=5, verbose=1)\n",
    "kfold = StratifiedKFold(n_splits=4)\n",
    "results = cross_val_score(estimator, x_bow, y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(Xp)):\n",
    "    for j in indices:\n",
    "        x_20[i][j] *= 2.0\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_20.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  0.  0.  0.  0.  0.  0.  0.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  2.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 3.  0.  0.  0.  0.  0.  0.  0.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  2.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(x_20[5])\n",
    "print(Xp[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_167 (Dense)            (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "14999/14999 [==============================] - 25s 2ms/step - loss: 0.4242 - acc: 0.7977\n",
      "Epoch 2/15\n",
      "14999/14999 [==============================] - 22s 1ms/step - loss: 0.3397 - acc: 0.8519\n",
      "Epoch 3/15\n",
      "14999/14999 [==============================] - 23s 2ms/step - loss: 0.3155 - acc: 0.8623\n",
      "Epoch 4/15\n",
      "14999/14999 [==============================] - 25s 2ms/step - loss: 0.2921 - acc: 0.8709\n",
      "Epoch 5/15\n",
      "14999/14999 [==============================] - 21s 1ms/step - loss: 0.2665 - acc: 0.8827\n",
      "Epoch 6/15\n",
      "14999/14999 [==============================] - 21s 1ms/step - loss: 0.2359 - acc: 0.8937\n",
      "Epoch 7/15\n",
      "14999/14999 [==============================] - 21s 1ms/step - loss: 0.1974 - acc: 0.9133\n",
      "Epoch 8/15\n",
      "14999/14999 [==============================] - 20s 1ms/step - loss: 0.1587 - acc: 0.9327\n",
      "Epoch 9/15\n",
      "14999/14999 [==============================] - 21s 1ms/step - loss: 0.1201 - acc: 0.9480\n",
      "Epoch 10/15\n",
      "14999/14999 [==============================] - 21s 1ms/step - loss: 0.0981 - acc: 0.9617\n",
      "Epoch 11/15\n",
      "14999/14999 [==============================] - 22s 1ms/step - loss: 0.0783 - acc: 0.9713\n",
      "Epoch 12/15\n",
      "14999/14999 [==============================] - 22s 1ms/step - loss: 0.0619 - acc: 0.9746\n",
      "Epoch 13/15\n",
      "14999/14999 [==============================] - 22s 1ms/step - loss: 0.0474 - acc: 0.9829\n",
      "Epoch 14/15\n",
      "14999/14999 [==============================] - 22s 1ms/step - loss: 0.0390 - acc: 0.9862\n",
      "Epoch 15/15\n",
      "14999/14999 [==============================] - 22s 1ms/step - loss: 0.0371 - acc: 0.9869\n",
      "5001/5001 [==============================] - 3s 689us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_171 (Dense)            (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "15000/15000 [==============================] - 25s 2ms/step - loss: 0.4142 - acc: 0.8061\n",
      "Epoch 2/15\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.3316 - acc: 0.8563\n",
      "Epoch 3/15\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.3078 - acc: 0.8649\n",
      "Epoch 4/15\n",
      "15000/15000 [==============================] - 10824s 722ms/step - loss: 0.2882 - acc: 0.8729\n",
      "Epoch 5/15\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.2640 - acc: 0.8816\n",
      "Epoch 6/15\n",
      "15000/15000 [==============================] - 3713s 248ms/step - loss: 0.2300 - acc: 0.8965\n",
      "Epoch 7/15\n",
      "15000/15000 [==============================] - 25s 2ms/step - loss: 0.1977 - acc: 0.9129\n",
      "Epoch 8/15\n",
      "15000/15000 [==============================] - 26s 2ms/step - loss: 0.1577 - acc: 0.9287\n",
      "Epoch 9/15\n",
      "15000/15000 [==============================] - 26s 2ms/step - loss: 0.1302 - acc: 0.9433\n",
      "Epoch 10/15\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.0955 - acc: 0.9590\n",
      "Epoch 11/15\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.0793 - acc: 0.9705\n",
      "Epoch 12/15\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.0577 - acc: 0.9773\n",
      "Epoch 13/15\n",
      "15000/15000 [==============================] - 22s 1ms/step - loss: 0.0500 - acc: 0.9817\n",
      "Epoch 14/15\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.0425 - acc: 0.9851\n",
      "Epoch 15/15\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.0364 - acc: 0.9875\n",
      "5000/5000 [==============================] - 5s 914us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_175 (Dense)            (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "15000/15000 [==============================] - 30s 2ms/step - loss: 0.4159 - acc: 0.8091\n",
      "Epoch 2/15\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.3278 - acc: 0.8607\n",
      "Epoch 3/15\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.3057 - acc: 0.8689\n",
      "Epoch 4/15\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.2821 - acc: 0.8784\n",
      "Epoch 5/15\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.2596 - acc: 0.8863\n",
      "Epoch 6/15\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.2264 - acc: 0.9015\n",
      "Epoch 7/15\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.1889 - acc: 0.9195\n",
      "Epoch 8/15\n",
      "15000/15000 [==============================] - 23s 2ms/step - loss: 0.1500 - acc: 0.9377\n",
      "Epoch 9/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.1153 - acc: 0.9503\n",
      "Epoch 10/15\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.0933 - acc: 0.9620\n",
      "Epoch 11/15\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.0744 - acc: 0.9711\n",
      "Epoch 12/15\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.0631 - acc: 0.9747\n",
      "Epoch 13/15\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.0468 - acc: 0.9817\n",
      "Epoch 14/15\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.0395 - acc: 0.9851\n",
      "Epoch 15/15\n",
      "15000/15000 [==============================] - 21s 1ms/step - loss: 0.0363 - acc: 0.9865\n",
      "5000/5000 [==============================] - 3s 680us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_179 (Dense)            (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 40)                5040      \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 286,706\n",
      "Trainable params: 286,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.4197 - acc: 0.8037\n",
      "Epoch 2/15\n",
      "15001/15001 [==============================] - 21s 1ms/step - loss: 0.3375 - acc: 0.8536\n",
      "Epoch 3/15\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.3129 - acc: 0.8601\n",
      "Epoch 4/15\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.2877 - acc: 0.8722\n",
      "Epoch 5/15\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.2582 - acc: 0.8849\n",
      "Epoch 6/15\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.2260 - acc: 0.8983\n",
      "Epoch 7/15\n",
      "15001/15001 [==============================] - 24s 2ms/step - loss: 0.1882 - acc: 0.9179\n",
      "Epoch 8/15\n",
      "15001/15001 [==============================] - 28s 2ms/step - loss: 0.1523 - acc: 0.9361\n",
      "Epoch 9/15\n",
      "15001/15001 [==============================] - 25s 2ms/step - loss: 0.1173 - acc: 0.9532\n",
      "Epoch 10/15\n",
      "15001/15001 [==============================] - 25s 2ms/step - loss: 0.0938 - acc: 0.9618\n",
      "Epoch 11/15\n",
      "15001/15001 [==============================] - 24s 2ms/step - loss: 0.0762 - acc: 0.9715\n",
      "Epoch 12/15\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.0588 - acc: 0.9781\n",
      "Epoch 13/15\n",
      "15001/15001 [==============================] - 23s 2ms/step - loss: 0.0460 - acc: 0.9833\n",
      "Epoch 14/15\n",
      "15001/15001 [==============================] - 27s 2ms/step - loss: 0.0398 - acc: 0.9856\n",
      "Epoch 15/15\n",
      "15001/15001 [==============================] - 24s 2ms/step - loss: 0.0313 - acc: 0.9885\n",
      "4999/4999 [==============================] - 4s 814us/step\n",
      "Results: 83.57% (0.41%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_model, epochs=15, batch_size=5, verbose=1)\n",
    "kfold = StratifiedKFold(n_splits=4)\n",
    "results = cross_val_score(estimator, x_20, y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
